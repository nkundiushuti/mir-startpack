{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW3seEK2yWPd"
   },
   "source": [
    "End-to-end classification using deep learning on the waveform\n",
    "============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cSJcgQwIrIq"
   },
   "source": [
    "## Installation of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GugsmRYH_72"
   },
   "source": [
    "First of all we need to find out if the notebook is run on Colab and, if so, what version of cuda we have on the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iidt0GzvHHxO",
    "outputId": "6568d5b9-d7ff-450a-c7f5-04565b2a42dc"
   },
   "outputs": [],
   "source": [
    "# RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "# if RunningInCOLAB:\n",
    "#   !nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFs_ZDemz3Vf"
   },
   "source": [
    "Then we install the pytorch version for the corresponding cuda version and the other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4ePrUY2yoCh",
    "outputId": "f4982ce9-5272-4166-fbed-5118504c9417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: torchvision in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: torchaudio in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (0.8.1)\r\n",
      "Requirement already satisfied: numpy in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from torch) (1.20.3)\r\n",
      "Requirement already satisfied: typing-extensions in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from torch) (3.10.0.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from torchvision) (8.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning==1.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (1.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.3 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (1.8.1)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (2.5.0)\r\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (2021.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (1.20.3)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (5.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (4.61.0)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pytorch-lightning==1.1) (0.18.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (1.30.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (2.25.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.6.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (3.17.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (0.4.4)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (1.38.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (1.8.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (0.36.2)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (0.12.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (53.0.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1) (3.3.4)\r\n",
      "Requirement already satisfied: six in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.1) (1.16.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1) (4.7.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1) (0.2.8)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1) (4.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1) (4.5.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1) (0.4.8)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1) (1.26.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1) (2021.5.30)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1) (2.10)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1) (3.1.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning==1.1) (3.10.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1) (3.4.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mirdata in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (0.3.4b2)\r\n",
      "Requirement already satisfied: scikit-learn in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (0.24.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.16 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (1.20.3)\r\n",
      "Requirement already satisfied: jams in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (0.3.4)\r\n",
      "Requirement already satisfied: tqdm in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (4.61.0)\r\n",
      "Requirement already satisfied: pretty-midi>=0.2.8 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (0.2.9)\r\n",
      "Requirement already satisfied: chardet in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (4.0.0)\r\n",
      "Requirement already satisfied: requests in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (2.25.1)\r\n",
      "Requirement already satisfied: librosa>=0.8.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (0.8.1)\r\n",
      "Requirement already satisfied: scipy in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mirdata) (1.6.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile>=0.10.2 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (0.10.3.post1)\r\n",
      "Requirement already satisfied: numba>=0.43.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (0.53.1)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (5.0.9)\r\n",
      "Requirement already satisfied: pooch>=1.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (1.3.0)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (1.0.1)\r\n",
      "Requirement already satisfied: resampy>=0.2.2 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (0.2.2)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (2.1.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from librosa>=0.8.0->mirdata) (20.9)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\r\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (0.36.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (53.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from packaging>=20.0->librosa>=0.8.0->mirdata) (2.4.7)\r\n",
      "Requirement already satisfied: appdirs in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pooch>=1.0->librosa>=0.8.0->mirdata) (1.4.4)\r\n",
      "Requirement already satisfied: six in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pretty-midi>=0.2.8->mirdata) (1.16.0)\r\n",
      "Requirement already satisfied: mido>=1.1.16 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pretty-midi>=0.2.8->mirdata) (1.2.10)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa>=0.8.0->mirdata) (1.14.5)\r\n",
      "Requirement already satisfied: pycparser in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->mirdata) (2.20)\r\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jams->mirdata) (3.2.0)\r\n",
      "Requirement already satisfied: mir-eval>=0.5 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jams->mirdata) (0.6)\r\n",
      "Requirement already satisfied: pandas in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jams->mirdata) (1.2.4)\r\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jams->mirdata) (2.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jsonschema>=3.0.0->jams->mirdata) (4.5.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jsonschema>=3.0.0->jams->mirdata) (20.3.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from jsonschema>=3.0.0->jams->mirdata) (0.17.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from mir-eval>=0.5->jams->mirdata) (0.18.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.0->jams->mirdata) (3.10.0.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.0->jams->mirdata) (3.4.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2017.3 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pandas->jams->mirdata) (2021.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from pandas->jams->mirdata) (2.8.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<3,>=2.5 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests->mirdata) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests->mirdata) (2021.5.30)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Volumes/storessd/Users/mariusmiron/opt/miniconda3/envs/startpack/lib/python3.7/site-packages (from requests->mirdata) (1.26.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip uninstall -y torchtext\n",
    "!pip install pytorch-lightning==1.1\n",
    "!pip install mirdata scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBrIMBt6Jm34"
   },
   "source": [
    "We import the packages and we set the random_seed for our experiments. The random seed makes sure the experiment is reproducible on this environment.\n",
    "\n",
    "We use mirdata to load the datasets, sklearn for data partitioning, torchaudio to load and transform audio files, and pytorch lightning on top of pytorch for machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pK5QL1yMHFmx",
    "outputId": "6e00325b-ba9b-4a05-e602-3f14b430b672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mirdata\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "random_seed=0\n",
    "pl.utilities.seed.seed_everything(seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pokcYI_tK2rO"
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkgW6tvrKeaL"
   },
   "source": [
    "We initialize Mridangam stroke a collection of 7162 audio examples of individual strokes of the Mridangam in various tonics. The dataset comprises of 10 different strokes played on Mridangams with 6 different tonic values. \n",
    "\n",
    "In this experiment we predict 10 stroke classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7y6vQl5UHOkV"
   },
   "outputs": [],
   "source": [
    "mridangam = mirdata.initialize(\"mridangam_stroke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvCFJiXFKhYk"
   },
   "source": [
    "First time the dataset needs to be downloaded. This is fairly easy with the public datasets in mirdata, by calling the download method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSG57fP2gqDI",
    "outputId": "d8723d44-e0b7-4a93-9cc4-6a383f6adc8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading ['remote_data'] to /Volumes/storessd/Users/mariusmiron/mir_datasets/mridangam_stroke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [remote_data] downloading mridangam_stroke_1.5.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: /Volumes/storessd/Users/mariusmiron/mir_datasets/mridangam_stroke/mridangam_stroke_1.5.zip already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n"
     ]
    }
   ],
   "source": [
    "mridangam.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yurv0W8K5nP",
    "outputId": "7a9afdbc-e703-454f-8ccf-e3e3c8d43939"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6976 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 298/6976 [00:00<00:02, 2978.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 645/6976 [00:00<00:01, 3261.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 972/6976 [00:00<00:01, 3188.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 1300/6976 [00:00<00:01, 3222.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 1623/6976 [00:00<00:01, 3036.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 1929/6976 [00:00<00:01, 2951.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 2226/6976 [00:00<00:01, 2704.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 2520/6976 [00:00<00:01, 2770.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2801/6976 [00:00<00:01, 2564.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 3099/6976 [00:01<00:01, 2678.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 3371/6976 [00:01<00:01, 2604.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 3710/6976 [00:01<00:01, 2823.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 4021/6976 [00:01<00:01, 2903.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 4354/6976 [00:01<00:00, 3020.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4691/6976 [00:01<00:00, 3123.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 5006/6976 [00:01<00:00, 3059.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 5363/6976 [00:01<00:00, 3207.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 5725/6976 [00:01<00:00, 3327.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 6073/6976 [00:02<00:00, 3371.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 6483/6976 [00:02<00:00, 3587.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 6848/6976 [00:02<00:00, 3604.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 6976/6976 [00:02<00:00, 3109.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Success: the dataset is complete and all files are valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track(\n",
      "  audio_path=\".../mariusmiron/mir_datasets/mridangam_stroke/mridangam_stroke_1.5/E/231180__akshaylaya__thom-e-077.wav\",\n",
      "  stroke_name=\"thom\",\n",
      "  tonic=\"E\",\n",
      "  track_id=\"231180\",\n",
      "  audio: The track's audio\n",
      "\n",
      "        Returns,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "mridangam.validate()  # validate dataset\n",
    "track = mridangam.choice_track()  # load a random track\n",
    "x, sr = track.audio\n",
    "ipd.Audio(track.audio_path)\n",
    "print(track)  # see what data a track contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzWTTqxmKtwE"
   },
   "source": [
    "\n",
    "In order to use this dataset with pytorch, we extend the Dataset object to load the audio and annotations in our dataset, according to these [instructions](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
    "\n",
    "We basically need to write three methods:\n",
    "\n",
    "\n",
    "*   __init__\n",
    "*   __len__\n",
    "*   __getitem__ to return each pair of audio array and class label\n",
    "\n",
    "\n",
    "This is how a prototype of this class could look like:\n",
    "\n",
    "```\n",
    "class MridangamDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "      self.track_ids = dataset.track_ids\n",
    "    def __getitem__(self, index):\n",
    "      # load data\n",
    "      audio = load_audio(self.track_ids[index])\n",
    "      label = self.track_ids[index].label\n",
    "      # split audio in a fixed size array\n",
    "      audio = audio[:seq_duration] \n",
    "      return audio,label\n",
    "    def __len__(self):\n",
    "      return len(self.tracks_ids)\n",
    "\n",
    "```\n",
    "\n",
    "Let's implement the class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "irATuWrpHblx"
   },
   "outputs": [],
   "source": [
    "class MridangamDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mirdataset,\n",
    "        seq_duration=0.5,\n",
    "        random_start=True,\n",
    "        resample=8000,\n",
    "        subset=0,\n",
    "        train_split=0.8,\n",
    "        test_split=0.2,\n",
    "        random_seed=42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.seq_duration = seq_duration\n",
    "        self.dataset = mirdataset\n",
    "        self.track_ids = self.dataset.track_ids\n",
    "        self.tracks = self.dataset.load_tracks()\n",
    "        self.resample = resample\n",
    "        self.set = subset\n",
    "        self.random_start = random_start\n",
    "\n",
    "        #### build a list with labels \n",
    "        labels = [self.dataset.track(i).stroke_name for i in self.track_ids]\n",
    "        unique_labels = list(set(labels)) ### unique labels\n",
    "        self.labels = {label:i for i,label in enumerate(unique_labels)}\n",
    "\n",
    "        #### build the three subsets: train, validation, test using train_test_split, a stratified split with the labels\n",
    "        self.trackids_train, self.trackids_test = sklearn.model_selection.train_test_split(self.track_ids, train_size=1-test_split, random_state=random_seed, stratify=labels)\n",
    "        train_labels = [l for l,i in zip(labels,self.track_ids) if i in self.trackids_train]\n",
    "        self.trackids_train, self.trackids_valid = sklearn.model_selection.train_test_split(self.trackids_train, train_size=train_split, random_state=random_seed, stratify=train_labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #### get the file with index in the corresponding subset\n",
    "        if self.set==0:\n",
    "            track_id = self.trackids_train[index]\n",
    "        elif self.set==1:\n",
    "            track_id = self.trackids_valid[index]\n",
    "        elif self.set==2:\n",
    "            track_id = self.trackids_test[index]\n",
    "        track = self.dataset.track(track_id)\n",
    "\n",
    "        #### compute start and end frames to read from the disk\n",
    "        # si, ei = torchaudio.info(track.audio_path)\n",
    "        # sample_rate, channels, length = si.rate, si.channels, si.length\n",
    "        ####alternative\n",
    "        metadata = torchaudio.info(track.audio_path)\n",
    "        sample_rate = metadata.sample_rate \n",
    "        channels = metadata.num_channels\n",
    "        length = metadata.num_frames\n",
    "        duration = length / sample_rate\n",
    "\n",
    "        \n",
    "        offset = 0\n",
    "        if self.seq_duration>duration:\n",
    "            num_frames = length\n",
    "        else:\n",
    "            num_frames = int(np.floor(self.seq_duration * sample_rate))\n",
    "\n",
    "\n",
    "        #### get audio frames corresponding to offset and num_frames from the disk\n",
    "        audio_signal, sample_rate = torchaudio.load(filepath=track.audio_path, frame_offset=offset,num_frames=num_frames)\n",
    "        #### alternative\n",
    "        #audio_signal, sample_rate = torchaudio.load(filepath=track.audio_path, offset=offset,num_frames=num_frames)\n",
    "\n",
    "        #### zero pad if the size is smaller than seq_duration\n",
    "        seq_duration_samples = int(self.seq_duration * sample_rate)\n",
    "        total_samples = audio_signal.shape[-1]\n",
    "        if seq_duration_samples>total_samples:\n",
    "            audio_signal = torch.nn.ConstantPad2d((0,seq_duration_samples-total_samples,0,0),0)(audio_signal)\n",
    "\n",
    "        #### resample\n",
    "        audio_signal = torchaudio.transforms.Resample(sample_rate, self.resample)(audio_signal)\n",
    "\n",
    "        return audio_signal, self.labels[track.stroke_name] \n",
    "\n",
    "    def __len__(self):\n",
    "        if self.set==0:\n",
    "            return len(self.trackids_train)\n",
    "        elif self.set==1:\n",
    "            return len(self.trackids_valid)\n",
    "        else:\n",
    "            return len(self.trackids_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM4Wk3tsRnqg"
   },
   "source": [
    "We initialize the dataset objects for train, validation, and test. We define the corresponding pytorch objects for data loading, defining the batch_size (paralellization on the GPU) and the num_workers ( data loading paralellization on CPU/memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "072HyKNfHs7q"
   },
   "outputs": [],
   "source": [
    "#### Pytorch dataset loaders\n",
    "train_dataset = MridangamDataset(mirdataset=mridangam,subset=0, random_seed=random_seed)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,num_workers=2,pin_memory=True)\n",
    "valid_dataset = MridangamDataset(mirdataset=mridangam,subset=1, random_seed=random_seed)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=64,num_workers=2,pin_memory=True)\n",
    "test_dataset = MridangamDataset(mirdataset=mridangam,subset=2, random_seed=random_seed)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRowsZK3HfDi"
   },
   "source": [
    "\n",
    "**Which batch size/learning rate?**\n",
    "\n",
    "Theory suggests that when multiplying the batch size by k, one should multiply the learning rate by sqrt(k) to keep the variance in the gradient expectation constant. See page 5 at A. Krizhevsky. One weird trick for parallelizing convolutional neural networks: https://arxiv.org/abs/1404.5997\n",
    "\n",
    "However, recent experiments with large mini-batches suggest for a simpler linear scaling rule, i.e multiply your learning rate by k when using mini-batch size of kN. See P.Goyal et al.: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour https://arxiv.org/abs/1706.02677"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Keh79hDpSUHG"
   },
   "source": [
    "## Training a pytorch lightning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpwMhNSUSrRJ"
   },
   "source": [
    "We extend the pytorch lightning module according to the [documentation](https://pytorch-lightning.readthedocs.io/en/stable/new-project.html). This may contain a definition of the layers in the neural network and how the data flows (how the layers are connected). You may overwrite other functions from `pl.LightningModule`, as described [here](https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html). The most important are `training_step` and `configure_optimizers`, in which we define the training loss and the optimizers.\n",
    "\n",
    "W = W - lr * Delta(W) -> Stochastic gradient descent\n",
    "W = [w1 ... w10] [l1...l10] \n",
    "\n",
    "```\n",
    ">>> class LitModel(pl.LightningModule):\n",
    "...\n",
    "...     def __init__(self):\n",
    "...         super().__init__()\n",
    "...         self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "...\n",
    "...     def forward(self, x):\n",
    "...         return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "...\n",
    "...     def training_step(self, batch, batch_idx):\n",
    "...         x, y = batch\n",
    "...         y_hat = self.forward(x)\n",
    "...         loss = F.cross_entropy(y_hat, y)\n",
    "...         return loss\n",
    "...\n",
    "...     def configure_optimizers(self):\n",
    "...         return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRF81_4YZ4cf"
   },
   "source": [
    "To predict the 10 classes of the Mridangam stroke dataset on the raw audio files, we train a version of the M5 neural network which has been used in speech command recognition using waveforms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vgBov7QIH3a8"
   },
   "outputs": [],
   "source": [
    "class M5(pl.LightningModule):\n",
    "    '''\n",
    "    M5 neural net taken from: https://pytorch.org/tutorials/intermediate/speech_command_recognition_with_torchaudio.html\n",
    "    '''\n",
    "    def __init__(self, n_input=1, n_output=10, stride=8, n_channel=32):\n",
    "        super().__init__()\n",
    "        #### network\n",
    "        self.conv1 = torch.nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = torch.nn.MaxPool1d(4)\n",
    "        self.conv2 = torch.nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = torch.nn.MaxPool1d(4)\n",
    "        self.conv3 = torch.nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = torch.nn.MaxPool1d(4)\n",
    "        self.conv4 = torch.nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = torch.nn.MaxPool1d(4)\n",
    "        self.fc1 = torch.nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "        #### metrics\n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        self.test_cm = pl.metrics.classification.ConfusionMatrix(num_classes=n_output)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        # x = torch.nn.functional.avg_pool1d(x) #, kernel_size=x.shape[-1],stride=1\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=2).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        ### why log softmax and nll loss: https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('train_loss', loss)\n",
    "        self.train_acc(output, label)\n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('val_loss', loss)\n",
    "        self.valid_acc(output, label)\n",
    "        self.log('valid_acc', self.valid_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('test_loss', loss)\n",
    "        self.test_acc(output, label)\n",
    "        self.log('test_acc', self.test_acc, on_step=True, on_epoch=True)\n",
    "        self.test_cm(output, label)\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # log epoch metric\n",
    "        self.log('train_acc', self.train_acc.compute(), prog_bar=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log('val_acc', self.valid_acc.compute(), prog_bar=True)\n",
    "\n",
    "    def get_progress_bar_dict(self):\n",
    "        # don't show the version number\n",
    "        items = super().get_progress_bar_dict()\n",
    "        items.pop(\"v_num\", None)\n",
    "        return items\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-2,weight_decay=0.0001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # reduce the learning after 10 epochs by a factor of 10\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBgC2yQhZdFx"
   },
   "source": [
    "We train the model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gzLG38D1H9XQ"
   },
   "outputs": [],
   "source": [
    "#### Initialize the model\n",
    "model = M5(n_input=train_dataset[0][0].shape[0], n_output=len(train_dataset.labels))\n",
    "\n",
    "#### Initialize a trainer\n",
    "#trainer = pl.Trainer(gpus=1, max_epochs=3, progress_bar_refresh_rate=10)\n",
    "\n",
    "#### Train the model\n",
    "#trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIg6fmr4Zj4c"
   },
   "source": [
    "Once the model is trained we can use it to process data, save it, get the metrics on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4l9QTVHAIJcx"
   },
   "outputs": [],
   "source": [
    "# #### Put the model in production\n",
    "# model.eval()\n",
    "\n",
    "# #### Compute metrics on the test set\n",
    "# trainer.test(test_dataloaders=test_loader)\n",
    "\n",
    "# #### Compute confusion matrix on the test set\n",
    "# confusion_matrix = model.test_cm.compute().cpu().numpy()\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.matshow(confusion_matrix)\n",
    "# ax.set_xticks(range(len(train_dataset.labels)))\n",
    "# ax.set_yticks(range(len(train_dataset.labels)))\n",
    "# ax.set_xticklabels(train_dataset.labels)\n",
    "# ax.set_yticklabels(train_dataset.labels)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy_End_to_end_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}