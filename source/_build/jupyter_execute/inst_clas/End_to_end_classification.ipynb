{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SW3seEK2yWPd"
   },
   "source": [
    "End-to-end classification using deep learning on the waveform\n",
    "============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cSJcgQwIrIq"
   },
   "source": [
    "## Installation of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GugsmRYH_72"
   },
   "source": [
    "First of all we need to find out if the notebook is run on Colab and, if so, what version of cuda we have on the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iidt0GzvHHxO",
    "outputId": "a9a46114-6136-48e2-afa3-1befd2483629"
   },
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "  !nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFs_ZDemz3Vf"
   },
   "source": [
    "Then we install the pytorch version for the corresponding cuda version and the other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R4ePrUY2yoCh"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip uninstall -y torchtext\n",
    "!pip install pytorch-lightning==1.1\n",
    "!pip install mirdata scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBrIMBt6Jm34"
   },
   "source": [
    "We import the packages and we set the random_seed for our experiments. The random seed makes sure the experiment is reproducible on this environment.\n",
    "\n",
    "We use mirdata to load the datasets, sklearn for data partitioning, torchaudio to load and transform audio files, and pytorch lightning on top of pytorch for machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pK5QL1yMHFmx",
    "outputId": "0146473a-80f0-4949-f543-08035a1d02c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mirdata\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "random_seed=0\n",
    "pl.utilities.seed.seed_everything(seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pokcYI_tK2rO"
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkgW6tvrKeaL"
   },
   "source": [
    "We initialize Mridangam stroke a collection of 7162 audio examples of individual strokes of the Mridangam in various tonics. The dataset comprises of 10 different strokes played on Mridangams with 6 different tonic values. \n",
    "\n",
    "In this experiment we predict 10 stroke classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7y6vQl5UHOkV"
   },
   "outputs": [],
   "source": [
    "mridangam = mirdata.initialize(\"mridangam_stroke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvCFJiXFKhYk"
   },
   "source": [
    "First time the dataset needs to be downloaded. This is fairly easy with the public datasets in mirdata, by calling the download method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSG57fP2gqDI",
    "outputId": "391cdf93-bbe8-46de-e1aa-c0086c95e979"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Downloading ['remote_data'] to /Volumes/storessd/Users/mariusmiron/mir_datasets/mridangam_stroke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [remote_data] downloading mridangam_stroke_1.5.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: /Volumes/storessd/Users/mariusmiron/mir_datasets/mridangam_stroke/mridangam_stroke_1.5.zip already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n"
     ]
    }
   ],
   "source": [
    "mridangam.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yurv0W8K5nP",
    "outputId": "c2d28bdd-2fb1-4510-da0b-7f2d445eac3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6976 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 251/6976 [00:00<00:02, 2505.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 502/6976 [00:00<00:02, 2443.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 747/6976 [00:00<00:02, 2408.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 991/6976 [00:00<00:02, 2417.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 1267/6976 [00:00<00:02, 2534.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 1521/6976 [00:00<00:02, 2417.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 1819/6976 [00:00<00:01, 2593.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 2095/6976 [00:00<00:01, 2644.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 2375/6976 [00:00<00:01, 2691.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 2645/6976 [00:01<00:01, 2410.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 2928/6976 [00:01<00:01, 2526.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 3228/6976 [00:01<00:01, 2660.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3517/6976 [00:01<00:01, 2724.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 3793/6976 [00:01<00:01, 2696.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 4065/6976 [00:01<00:01, 2690.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 4341/6976 [00:01<00:00, 2707.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 4613/6976 [00:01<00:01, 2028.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 4842/6976 [00:02<00:01, 1737.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 5039/6976 [00:02<00:01, 1655.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 5221/6976 [00:02<00:01, 1676.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 5424/6976 [00:02<00:00, 1762.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 5611/6976 [00:02<00:01, 1312.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5799/6976 [00:02<00:00, 1432.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 5964/6976 [00:02<00:00, 1482.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 6155/6976 [00:02<00:00, 1587.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 6327/6976 [00:03<00:00, 1498.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 6509/6976 [00:03<00:00, 1540.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 6756/6976 [00:03<00:00, 1784.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 6976/6976 [00:03<00:00, 2056.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Success: the dataset is complete and all files are valid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track(\n",
      "  audio_path=\".../mariusmiron/mir_datasets/mridangam_stroke/mridangam_stroke_1.5/E/231180__akshaylaya__thom-e-077.wav\",\n",
      "  stroke_name=\"thom\",\n",
      "  tonic=\"E\",\n",
      "  track_id=\"231180\",\n",
      "  audio: The track's audio\n",
      "\n",
      "        Returns,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "mridangam.validate()  # validate dataset\n",
    "track = mridangam.choice_track()  # load a random track\n",
    "x, sr = track.audio\n",
    "ipd.Audio(track.audio_path)\n",
    "print(track)  # see what data a track contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzWTTqxmKtwE"
   },
   "source": [
    "\n",
    "In order to use this dataset with pytorch, we extend the Dataset object to load the audio and annotations in our dataset, according to these [instructions](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
    "\n",
    "We basically need to write three methods:\n",
    "\n",
    "\n",
    "*   __init__\n",
    "*   __len__\n",
    "*   __getitem__ to return each pair of audio array and class label\n",
    "\n",
    "\n",
    "This is how a prototype of this class could look like:\n",
    "\n",
    "```\n",
    "class MridangamDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "      self.track_ids = dataset.track_ids\n",
    "    def __getitem__(self, index):\n",
    "      # load data\n",
    "      audio = load_audio(self.track_ids[index])\n",
    "      label = self.track_ids[index].label\n",
    "      # split audio in a fixed size array\n",
    "      audio = audio[:seq_duration] \n",
    "      return audio,label\n",
    "    def __len__(self):\n",
    "      return len(self.tracks_ids)\n",
    "\n",
    "```\n",
    "\n",
    "Let's implement the class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "irATuWrpHblx"
   },
   "outputs": [],
   "source": [
    "class MridangamDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mirdataset,\n",
    "        seq_duration=0.5,\n",
    "        random_start=True,\n",
    "        resample=8000,\n",
    "        subset=0,\n",
    "        train_split=0.8,\n",
    "        test_split=0.2,\n",
    "        random_seed=42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.seq_duration = seq_duration\n",
    "        self.dataset = mirdataset\n",
    "        self.track_ids = self.dataset.track_ids\n",
    "        self.tracks = self.dataset.load_tracks()\n",
    "        self.resample = resample\n",
    "        self.set = subset\n",
    "        self.random_start = random_start\n",
    "\n",
    "        #### build a list with labels \n",
    "        labels = [self.dataset.track(i).stroke_name for i in self.track_ids]\n",
    "        unique_labels = list(set(labels)) ### unique labels\n",
    "        self.labels = {label:i for i,label in enumerate(unique_labels)}\n",
    "\n",
    "        #### build the three subsets: train, validation, test using train_test_split, a stratified split with the labels\n",
    "        self.trackids_train, self.trackids_test = sklearn.model_selection.train_test_split(self.track_ids, train_size=1-test_split, random_state=random_seed, stratify=labels)\n",
    "        train_labels = [l for l,i in zip(labels,self.track_ids) if i in self.trackids_train]\n",
    "        self.trackids_train, self.trackids_valid = sklearn.model_selection.train_test_split(self.trackids_train, train_size=train_split, random_state=random_seed, stratify=train_labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #### get the file with index in the corresponding subset\n",
    "        if self.set==0:\n",
    "            track_id = self.trackids_train[index]\n",
    "        elif self.set==1:\n",
    "            track_id = self.trackids_valid[index]\n",
    "        elif self.set==2:\n",
    "            track_id = self.trackids_test[index]\n",
    "        track = self.dataset.track(track_id)\n",
    "\n",
    "        #### compute start and end frames to read from the disk\n",
    "        # si, ei = torchaudio.info(track.audio_path)\n",
    "        # sample_rate, channels, length = si.rate, si.channels, si.length\n",
    "        ####alternative\n",
    "        metadata = torchaudio.info(track.audio_path)\n",
    "        sample_rate = metadata.sample_rate \n",
    "        channels = metadata.num_channels\n",
    "        length = metadata.num_frames\n",
    "        duration = length / sample_rate\n",
    "\n",
    "        \n",
    "        offset = 0\n",
    "        if self.seq_duration>duration:\n",
    "            num_frames = length\n",
    "        else:\n",
    "            num_frames = int(np.floor(self.seq_duration * sample_rate))\n",
    "\n",
    "\n",
    "        #### get audio frames corresponding to offset and num_frames from the disk\n",
    "        audio_signal, sample_rate = torchaudio.load(filepath=track.audio_path, frame_offset=offset,num_frames=num_frames)\n",
    "        #### alternative\n",
    "        #audio_signal, sample_rate = torchaudio.load(filepath=track.audio_path, offset=offset,num_frames=num_frames)\n",
    "\n",
    "        #### zero pad if the size is smaller than seq_duration\n",
    "        seq_duration_samples = int(self.seq_duration * sample_rate)\n",
    "        total_samples = audio_signal.shape[-1]\n",
    "        if seq_duration_samples>total_samples:\n",
    "            audio_signal = torch.nn.ConstantPad2d((0,seq_duration_samples-total_samples,0,0),0)(audio_signal)\n",
    "\n",
    "        #### resample\n",
    "        audio_signal = torchaudio.transforms.Resample(sample_rate, self.resample)(audio_signal)\n",
    "\n",
    "        return audio_signal, self.labels[track.stroke_name] \n",
    "\n",
    "    def __len__(self):\n",
    "        if self.set==0:\n",
    "            return len(self.trackids_train)\n",
    "        elif self.set==1:\n",
    "            return len(self.trackids_valid)\n",
    "        else:\n",
    "            return len(self.trackids_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM4Wk3tsRnqg"
   },
   "source": [
    "We initialize the dataset objects for train, validation, and test. We define the corresponding pytorch objects for data loading, defining the batch_size (paralellization on the GPU) and the num_workers ( data loading paralellization on CPU/memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "072HyKNfHs7q"
   },
   "outputs": [],
   "source": [
    "#### Pytorch dataset loaders\n",
    "train_dataset = MridangamDataset(mirdataset=mridangam,subset=0, random_seed=random_seed)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,num_workers=2,pin_memory=True)\n",
    "valid_dataset = MridangamDataset(mirdataset=mridangam,subset=1, random_seed=random_seed)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=64,num_workers=2,pin_memory=True)\n",
    "test_dataset = MridangamDataset(mirdataset=mridangam,subset=2, random_seed=random_seed)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRowsZK3HfDi"
   },
   "source": [
    "\n",
    "**Which batch size/learning rate?**\n",
    "\n",
    "Theory suggests that when multiplying the batch size by k, one should multiply the learning rate by sqrt(k) to keep the variance in the gradient expectation constant. See page 5 at A. Krizhevsky. One weird trick for parallelizing convolutional neural networks: https://arxiv.org/abs/1404.5997\n",
    "\n",
    "However, recent experiments with large mini-batches suggest for a simpler linear scaling rule, i.e multiply your learning rate by k when using mini-batch size of kN. See P.Goyal et al.: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour https://arxiv.org/abs/1706.02677"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Keh79hDpSUHG"
   },
   "source": [
    "## Training a pytorch lightning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpwMhNSUSrRJ"
   },
   "source": [
    "We extend the pytorch lightning module according to the [documentation](https://pytorch-lightning.readthedocs.io/en/stable/new-project.html). This may contain a definition of the layers in the neural network and how the data flows (how the layers are connected). You may overwrite other functions from `pl.LightningModule`, as described [here](https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html). The most important are `training_step` and `configure_optimizers`, in which we define the training loss and the optimizers.\n",
    "\n",
    "W = W - lr * Delta(W) -> Stochastic gradient descent\n",
    "W = [w1 ... w10] [l1...l10] \n",
    "\n",
    "```\n",
    ">>> class LitModel(pl.LightningModule):\n",
    "...\n",
    "...     def __init__(self):\n",
    "...         super().__init__()\n",
    "...         self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "...\n",
    "...     def forward(self, x):\n",
    "...         return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "...\n",
    "...     def training_step(self, batch, batch_idx):\n",
    "...         x, y = batch\n",
    "...         y_hat = self.forward(x)\n",
    "...         loss = F.cross_entropy(y_hat, y)\n",
    "...         return loss\n",
    "...\n",
    "...     def configure_optimizers(self):\n",
    "...         return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRF81_4YZ4cf"
   },
   "source": [
    "To predict the 10 classes of the Mridangam stroke dataset on the raw audio files, we train a version of the M5 neural network which has been used in speech command recognition using waveforms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vgBov7QIH3a8"
   },
   "outputs": [],
   "source": [
    "class M5(pl.LightningModule):\n",
    "    '''\n",
    "    M5 neural net taken from: https://pytorch.org/tutorials/intermediate/speech_command_recognition_with_torchaudio.html\n",
    "    '''\n",
    "    def __init__(self, n_input=1, n_output=10, stride=8, n_channel=32):\n",
    "        super().__init__()\n",
    "        #### network\n",
    "        self.conv1 = torch.nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = torch.nn.MaxPool1d(4)\n",
    "        self.conv2 = torch.nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = torch.nn.MaxPool1d(4)\n",
    "        self.conv3 = torch.nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = torch.nn.MaxPool1d(4)\n",
    "        self.conv4 = torch.nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = torch.nn.MaxPool1d(4)\n",
    "        self.fc1 = torch.nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "        #### metrics\n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        self.test_cm = pl.metrics.classification.ConfusionMatrix(num_classes=n_output)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        # x = torch.nn.functional.avg_pool1d(x) #, kernel_size=x.shape[-1],stride=1\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=2).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        ### why log softmax and nll loss: https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('train_loss', loss)\n",
    "        self.train_acc(output, label)\n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('val_loss', loss)\n",
    "        self.valid_acc(output, label)\n",
    "        self.log('valid_acc', self.valid_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        waveform, label = batch\n",
    "        output = self.forward(waveform)\n",
    "        loss = torch.nn.functional.nll_loss(output, label)\n",
    "        self.log('test_loss', loss)\n",
    "        self.test_acc(output, label)\n",
    "        self.log('test_acc', self.test_acc, on_step=True, on_epoch=True)\n",
    "        self.test_cm(output, label)\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # log epoch metric\n",
    "        self.log('train_acc', self.train_acc.compute(), prog_bar=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log('val_acc', self.valid_acc.compute(), prog_bar=True)\n",
    "\n",
    "    def get_progress_bar_dict(self):\n",
    "        # don't show the version number\n",
    "        items = super().get_progress_bar_dict()\n",
    "        items.pop(\"v_num\", None)\n",
    "        return items\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-2,weight_decay=0.0001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # reduce the learning after 10 epochs by a factor of 10\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBgC2yQhZdFx"
   },
   "source": [
    "We train the model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzLG38D1H9XQ",
    "outputId": "704d7d5c-d39f-405f-d1eb-51e041d57761"
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "\n                You requested GPUs: [0]\n                But your machine only has: []\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a15e17f6ead4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#### Initialize a trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#### Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/startpack/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/env_vars_connector.py\u001b[0m in \u001b[0;36moverwrite_by_env_vars\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moverwrite_by_env_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/startpack/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, callbacks, default_root_dir, gradient_clip_val, process_position, num_nodes, num_processes, gpus, auto_select_gpus, tpu_cores, log_gpu_memory, progress_bar_refresh_rate, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, limit_train_batches, limit_val_batches, limit_test_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, sync_batchnorm, precision, weights_summary, weights_save_path, num_sanity_val_steps, truncated_bptt_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, terminate_on_nan, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, distributed_backend, automatic_optimization, move_metrics_to_cpu, enable_pl_optimizer)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mreplace_sampler_ddp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         )\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/startpack/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator_connector.py\u001b[0m in \u001b[0;36mon_trainer_init\u001b[0;34m(self, num_processes, tpu_cores, accelerator, distributed_backend, auto_select_gpus, gpus, num_nodes, log_gpu_memory, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick_multiple_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel_device_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_root_gpu_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/startpack/lib/python3.7/site-packages/pytorch_lightning/utilities/device_parser.py\u001b[0m in \u001b[0;36mparse_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPUs requested but none are available.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/startpack/lib/python3.7/site-packages/pytorch_lightning/utilities/device_parser.py\u001b[0m in \u001b[0;36m_sanitize_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mYou\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mBut\u001b[0m \u001b[0myour\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0monly\u001b[0m \u001b[0mhas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mall_available_gpus\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \"\"\")\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: \n                You requested GPUs: [0]\n                But your machine only has: []\n            "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "#### Initialize the model\n",
    "model = M5(n_input=train_dataset[0][0].shape[0], n_output=len(train_dataset.labels))\n",
    "\n",
    "#### Initialize a trainer\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=10, progress_bar_refresh_rate=10)\n",
    "\n",
    "#### Train the model\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIg6fmr4Zj4c"
   },
   "source": [
    "Once the model is trained we can use it to process data, save it, get the metrics on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sRfkS5lmj_4T"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4e380e4ed02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#### Compute metrics on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "#### Put the model in production\n",
    "model.eval()\n",
    "\n",
    "#### Compute metrics on the test set\n",
    "trainer.test(test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "4l9QTVHAIJcx",
    "outputId": "2ba5ebf0-22b3-4471-8f7b-c0cd7a65218e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Volumes/Macintosh HD 2/Documents/git/mir-startpack/source/_build/jupyter_execute/inst_clas/End_to_end_classification_27_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Compute confusion matrix on the test set\n",
    "confusion_matrix = model.test_cm.compute().cpu().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(confusion_matrix)\n",
    "ax.set_xticks(range(len(train_dataset.labels)))\n",
    "ax.set_yticks(range(len(train_dataset.labels)))\n",
    "ax.set_xticklabels(train_dataset.labels)\n",
    "ax.set_yticklabels(train_dataset.labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "End_to_end_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}